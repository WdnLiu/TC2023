{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gHPcg59zjr6"
      },
      "source": [
        "Theory of Computation 2023 - Horacio Saggion\n",
        "\n",
        "Deliverable Regular Expressions\n",
        "\n",
        "\n",
        "Please indicate the full names and NIAs of the team members as well as the team number\n",
        "\n",
        "TEAM: 19\n",
        "\n",
        "MEMBERS: 254748, 252074\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGcudUS8K4Jl"
      },
      "outputs": [],
      "source": [
        "# If using Colaborate then allow Google to use your data files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YA1x6iboL-8o"
      },
      "outputs": [],
      "source": [
        "#cd to the directory in drive you will use (change to your shared folder)\n",
        "%cd /content/drive/Shareddrives/ToC-2023/DELIVS/DELIV-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_zqQQX_DMHx3"
      },
      "outputs": [],
      "source": [
        "# reading some data using the pandas library\n",
        "import pandas as pd\n",
        "\n",
        "my_data=pd.read_csv('DATA/ToC_2023_REs.csv', sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PrZLazXSMs-r"
      },
      "outputs": [],
      "source": [
        "# the data is from twitter so it will contain interesting content\n",
        "# we only need the column 'text' to work with\n",
        "twitter_data=my_data['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-qgurvr6NA7W"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    @CSBAGUGANDA @FOWODE_UGANDA  linking the globa...\n",
            "1    .@Empower_Women Agree it's abt #SDG17: #ICT &a...\n",
            "2    Who agrees w/ me? #Goal2 makes much #SocioEcon...\n",
            "3    #SDG2 wants to end hunger by 2030. A challenge...\n",
            "4    The #SDGs must aim for progress for everyone, ...\n",
            "5    Awesome! Yours is a movement geared towards ac...\n",
            "6    Some good tips for #SDG3. Political commitment...\n",
            "7    Our Collective Global Future: Children &amp; U...\n",
            "8    ☛ @SDSNYouth: #SDG6 Ensure availability and su...\n",
            "9    +  in all its dimensions according to national...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# (1) TODO print 10 lines of the data to understand what type of text we are working with\n",
        "ten_lines = twitter_data.head(10)\n",
        "\n",
        "print(ten_lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWqVvz4x0t_G"
      },
      "source": [
        "(2) TODO: Understanding Regular\n",
        "\n",
        "Using the notation used in theory write regular expressions for\n",
        "\n",
        "\n",
        "1. zero or more 'a'\n",
        "2. one or more 'a'\n",
        "1. starts with a and it is followed by zero or more b's\n",
        "2. a sequence of one or more digits\n",
        "2. two digits followed by a - followed by two digits\n",
        "1. string of a's of odd length\n",
        "2. string of a's of even length\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. $(a)^{*}$\n",
        "2. $(a)^{+}$\n",
        "3. $a(b)^{*}$\n",
        "4. $(1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 0)^{+}$\n",
        "5. $(1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 0)^{2}a(1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 0)^{2}$\n",
        "6. $a(aa)^{*}$\n",
        "7. $(aa)^{*}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "yDJhBF85JwUs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "['EF', 'XY']\n",
            "['A', 'EFG', 'XYZ']\n",
            "<re.Match object; span=(46, 47), match='A'>\n"
          ]
        }
      ],
      "source": [
        "# (3)  TODO: Run the following code comment what the program is doing\n",
        "\n",
        "import re\n",
        "\n",
        "my_text =  ''' \"aaa bbb abcd yz\n",
        "\n",
        "123 4567\n",
        "\n",
        "\n",
        "2   4 5 7 8 90\n",
        "\n",
        "Abc dEFG XYZ\n",
        "\" '''\n",
        "\n",
        "#  What are we searching for?\n",
        "#  re.compile looks for any sequence of two letters (upper or lower case) and stores them as objects that can be operated on using methods.\n",
        "#  In the case of abcd we have two combinations in a row, the program will take the last sequence that satisfies our demand.\n",
        "\n",
        "my_regex=re.compile(r'(a-zA-Z][a-zA-Z])+')\n",
        "\n",
        "result=my_regex.findall(my_text)\n",
        "\n",
        "\n",
        "\n",
        "print(result)\n",
        "\n",
        "# TODO: What are we searching for?\n",
        "# re.compile looks for any sequence of two uppercase letters and stores them as objects that can be operated on using methods.\n",
        "\n",
        "my_regex=re.compile(r'([A-Z][A-Z])+')\n",
        "\n",
        "result=my_regex.findall(my_text)\n",
        "\n",
        "print(result)\n",
        "\n",
        "#  TODO: What are we searching for?\n",
        "# re.compile looks for any sequence of one or more uppercase letters and stores them as objects that can be operated on using methods.\n",
        "\n",
        "my_regex=re.compile(r'([A-Z][A-Z]*)')\n",
        "\n",
        "result=my_regex.findall(my_text)\n",
        "\n",
        "print(result)\n",
        "\n",
        "\n",
        "\n",
        "# TODO: What is the difference with the above?\n",
        "#The following uses re.search, which finds the first occurrence of the input string, instead of printing the strings that satisfy the condition\n",
        "#it prints whether it has matched, the span, which is a tuple containing the starting index and the last index of the coincidence and the string matched.\n",
        "\n",
        "result = re.search(r'([A-Z][A-Z]*)', my_text)\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dpm1qvtjJMP1"
      },
      "source": [
        "TODO: Take the tutorial  at [W3Schools on regular expressions in Python](https://www.w3schools.com/python/python_regex.asp)\n",
        "and practice the code.*texto en cursiva*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfXmYXThJlNi"
      },
      "source": [
        "(4) TODO: Answer the following questions about RE in python\n",
        "\n",
        "\n",
        "\n",
        "1.  What is the purpose of the findall function\n",
        "2.  What is the pupose of the search function\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. findall() returns a list with all the matches.\n",
        "2. search() looks for strings that match the condition and returns a Match Object in case it founds one. In case it founds more than one match it will just take the first one. Returns None if it does not find a match. The return Match has a tuple span that contains the starting and last index of the match, and the string of the match.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "Dh6Tz0KTOowX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "☛Join @HeforShe, a solidarity movement for #genderequality♀♂\n",
            "#SDGs #SDG5\n",
            "http://t.co/U5S8qS6dlB\n",
            "v @UN4Youth \n",
            "#Planet5050 #MenEngage\n",
            "#Africa\n"
          ]
        }
      ],
      "source": [
        "# (5) TODO: examine item 95 of the data\n",
        "item95 = twitter_data[95]\n",
        "print(item95)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "JBZpOMGJPk3n"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "expected string or bytes-like object, got 'Series'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/wdn/Documents/TC2023/RE_assignment_notebook_ToC_2023_with_numbers.ipynb Cell 14\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/wdn/Documents/TC2023/RE_assignment_notebook_ToC_2023_with_numbers.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m first100 \u001b[39m=\u001b[39m twitter_data\u001b[39m.\u001b[39mhead(\u001b[39m100\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/wdn/Documents/TC2023/RE_assignment_notebook_ToC_2023_with_numbers.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m my_regex \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mcompile(\u001b[39m\"\u001b[39m\u001b[39m2030\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/wdn/Documents/TC2023/RE_assignment_notebook_ToC_2023_with_numbers.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m result \u001b[39m=\u001b[39m my_regex\u001b[39m.\u001b[39;49mfindall(first100)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/wdn/Documents/TC2023/RE_assignment_notebook_ToC_2023_with_numbers.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(result)\n",
            "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object, got 'Series'"
          ]
        }
      ],
      "source": [
        "# (6) TODO: list sentences with string 2030 in the first 100 sentences of your data using a regular expression\n",
        "first100 = twitter_data.head(100)\n",
        "\n",
        "my_regex = re.compile(\"2030\")\n",
        "\n",
        "\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amGGdho6QT9x"
      },
      "outputs": [],
      "source": [
        "# (7) TODO: list sentences with string 2030 in the first 100 sentences of your data\n",
        "# this time 2030 should be a full word not part of a word\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9V1euKcIRRx-"
      },
      "outputs": [],
      "source": [
        "# (8) TODO:  find all sentences, within the first 100 sentences,  containing  a twitter hash tag '#' using regular expressions\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijoQCwsYctYe"
      },
      "outputs": [],
      "source": [
        "# install library NLTK to  work with texts\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7v1f7hMdC1g"
      },
      "outputs": [],
      "source": [
        "# import stopwords and punctuation for English\n",
        "import nltk\n",
        "stops=nltk.download('stopwords')\n",
        "punkt=nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aHDvPamciXx"
      },
      "outputs": [],
      "source": [
        "# word tokenization with nltk\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "text = \"Oh!!! I can't believe it is Friday.\"\n",
        "print(word_tokenize(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZRkwjJddl_W"
      },
      "outputs": [],
      "source": [
        "# (9) TODO tokenizing text vs tokenizing tweets\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "# produce a tokenization using word_tokenize(...) and a tokenization using the tweet tokenizer ( TweetTokenizer() )\n",
        "\n",
        "# How are they different?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvqeoFnAfVo8"
      },
      "outputs": [],
      "source": [
        "#  (10) TODO: what do you get if you tokenize item 95 of the data, show the tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Co2_FitMhWRs"
      },
      "outputs": [],
      "source": [
        "# (11) TODO: using a regular expression list  the emojis ☛   ♀  or ♂  and the position in which the occur\n",
        "# You should use the UNICODE representation of such emojis, which you can figure out checking a table or using\n",
        "# print(format(ord(CHARACTER), '#08x'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nav-_y5jb5sf"
      },
      "outputs": [],
      "source": [
        "# (12) TODO: extract all hashtags in first 100 sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmRllXHWTSDj"
      },
      "outputs": [],
      "source": [
        "# (13) TODO: extract only the TAG of the hashtag in the first 100 sentences\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NdPPFQCf3EM"
      },
      "outputs": [],
      "source": [
        "# (14) TODO: list all hashtags which include a year (something that looks like YYYY)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WipAUhfUCT9"
      },
      "outputs": [],
      "source": [
        "# (15) TODO: for all hashtags including a year, extract the year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05SpXJ5QoSlD"
      },
      "outputs": [],
      "source": [
        "# (16) TODO:  for all hashtags including a year, extract the year, list each year once"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "694J_vwO4IUF"
      },
      "outputs": [],
      "source": [
        "# (17) TODO: find all user mentions in the first 1000 sentences\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMV6Sbjv4mxL"
      },
      "outputs": [],
      "source": [
        "#  (18) TODO: find all user mentions such that contain UPPERCASE letters only, in the first 1000 sentences\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ruZ9sM28tsQ"
      },
      "outputs": [],
      "source": [
        "# (19) TODO: find all strings containing the substring UN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLZ_qxcw9aRP"
      },
      "outputs": [],
      "source": [
        "# (20)  TODO: find all strings containing the substring UN strictly in the middle of the token\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nx-d8JmW9t-K"
      },
      "outputs": [],
      "source": [
        "# (21) TODO: find all strings containing just numbers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ekoRz_y-CCu"
      },
      "outputs": [],
      "source": [
        "# (22) TODO: find all strings containing no numbers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s42UbWXEDTxI"
      },
      "outputs": [],
      "source": [
        "# (23) TODO: find any string between double quotes in the sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQlNBZDSE_R5"
      },
      "outputs": [],
      "source": [
        "# (24) TODO: extract all urls in the 100 first sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhi6l_M7HWR5"
      },
      "outputs": [],
      "source": [
        "# (25) TODO: extract all dates (can be DD/MM/YY or DD/MM/YYYY)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mguuUvi296x"
      },
      "outputs": [],
      "source": [
        "# (26) TODO: consider the following list of UNICODEs for emojis\n",
        "emojis=['\\U0001F603', '\\U0001F604', '\\U0001F601', '\\U0001F606', '\\U0001F605', '\\U0001F923',\n",
        "\t\t'\\U0001F602', '\\U0001F642', '\\U0001F643', '\\U0001F609', '\\U0001F60A', '\\U0001F607']\n",
        "\n",
        "# print them to understand what they are\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dydH4Gcl6hR6"
      },
      "outputs": [],
      "source": [
        "# (27)  TODO: use regular expression to find and list any sentence containing at least one of the emojis above\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XnwDAHtXrFo"
      },
      "outputs": [],
      "source": [
        "# (28) TODO: use regular expressions to find and extract all ocurrences of  previous emojis and count how many of each\n",
        "# list the results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mMvup0uQaMRb"
      },
      "outputs": [],
      "source": [
        "# (29) TODO: identify any sentences with 2 emojis in sequence such as 😊😊\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stZ1-ioUJiJT"
      },
      "outputs": [],
      "source": [
        "# (30) TODO: identify any sentences with 3 emojis in sequence such as 😊😊"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
